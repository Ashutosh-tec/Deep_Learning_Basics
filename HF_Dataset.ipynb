{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# DLP week-1\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6EXdJDmIxHxN",
        "outputId": "9e51500a-11fe-40a2-ba51-7a7cfc9301a0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: datasets in /usr/local/lib/python3.10/dist-packages (3.0.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from datasets) (3.16.1)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from datasets) (1.26.4)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (17.0.0)\n",
            "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.3.8)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets) (2.1.4)\n",
            "Requirement already satisfied: requests>=2.32.2 in /usr/local/lib/python3.10/dist-packages (from datasets) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.66.3 in /usr/local/lib/python3.10/dist-packages (from datasets) (4.66.5)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.10/dist-packages (from datasets) (3.5.0)\n",
            "Requirement already satisfied: multiprocess in /usr/local/lib/python3.10/dist-packages (from datasets) (0.70.16)\n",
            "Requirement already satisfied: fsspec<=2024.6.1,>=2023.1.0 in /usr/local/lib/python3.10/dist-packages (from fsspec[http]<=2024.6.1,>=2023.1.0->datasets) (2024.6.1)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets) (3.10.5)\n",
            "Requirement already satisfied: huggingface-hub>=0.22.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.24.7)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from datasets) (24.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from datasets) (6.0.2)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (2.4.0)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (24.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (6.1.0)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.11.1)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (4.0.3)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.22.0->datasets) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (2024.8.30)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2024.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.16.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install datasets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PDnA1aMpvVQ3"
      },
      "outputs": [],
      "source": [
        "from datasets import get_dataset_config_names, get_dataset_split_names, load_dataset, load_dataset_builder"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D6xcYcxovZzG",
        "outputId": "9c76c291-b4ca-4fd7-f03e-8ae10bbf777f"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['as', 'bn', 'gu', 'hi', 'kn', 'ml', 'mr', 'or', 'pa', 'ta', 'te']"
            ]
          },
          "execution_count": 104,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "get_dataset_config_names(\"ai4bharat/naamapadam\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yb7WKoMxxQ_Z",
        "outputId": "85925b12-8425-4420-c511-906f86d4a3f1"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'tokens': Sequence(feature=Value(dtype='string', id=None), length=-1, id=None),\n",
              " 'ner_tags': Sequence(feature=ClassLabel(names=['O', 'B-PER', 'I-PER', 'B-ORG', 'I-ORG', 'B-LOC', 'I-LOC'], id=None), length=-1, id=None)}"
            ]
          },
          "execution_count": 105,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "ds_builder = load_dataset_builder(\"ai4bharat/naamapadam\", \"hi\")\n",
        "\n",
        "ds_builder.info.description\n",
        "\n",
        "ds_builder.info.features"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RL5e7Y0yyjdp"
      },
      "outputs": [],
      "source": [
        "ds = load_dataset(\"ai4bharat/naamapadam\", \"ta\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5dXEs3DUy18h",
        "outputId": "e2b273c4-a1c8-4521-ef46-c2950b16f15f"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "DatasetDict({\n",
              "    train: Dataset({\n",
              "        features: ['tokens', 'ner_tags'],\n",
              "        num_rows: 497882\n",
              "    })\n",
              "    test: Dataset({\n",
              "        features: ['tokens', 'ner_tags'],\n",
              "        num_rows: 758\n",
              "    })\n",
              "    validation: Dataset({\n",
              "        features: ['tokens', 'ner_tags'],\n",
              "        num_rows: 2795\n",
              "    })\n",
              "})"
            ]
          },
          "execution_count": 107,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "ds"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "elrbuKP-0nix"
      },
      "source": [
        "# Q2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EH6vF4-_y3dX",
        "outputId": "f079037a-4e26-4d0e-d1fb-5cbf4f5c9e16"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'train': [{'filename': '/root/.cache/huggingface/datasets/ai4bharat___naamapadam/ta/1.0.0/9d4f21ac57d11ed4f9ea64854fdc9f5618e61acc/naamapadam-train.arrow'}],\n",
              " 'test': [{'filename': '/root/.cache/huggingface/datasets/ai4bharat___naamapadam/ta/1.0.0/9d4f21ac57d11ed4f9ea64854fdc9f5618e61acc/naamapadam-test.arrow'}],\n",
              " 'validation': [{'filename': '/root/.cache/huggingface/datasets/ai4bharat___naamapadam/ta/1.0.0/9d4f21ac57d11ed4f9ea64854fdc9f5618e61acc/naamapadam-validation.arrow'}]}"
            ]
          },
          "execution_count": 108,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "ds.cache_files"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TiOoj5PW0qSR"
      },
      "source": [
        "# Q3"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CGruNLF_0Djx",
        "outputId": "e34dfbf9-e2ad-40e9-b8e4-9f7b969cdb54"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['__class__',\n",
              " '__class_getitem__',\n",
              " '__contains__',\n",
              " '__delattr__',\n",
              " '__delitem__',\n",
              " '__dict__',\n",
              " '__dir__',\n",
              " '__doc__',\n",
              " '__enter__',\n",
              " '__eq__',\n",
              " '__exit__',\n",
              " '__format__',\n",
              " '__ge__',\n",
              " '__getattribute__',\n",
              " '__getitem__',\n",
              " '__gt__',\n",
              " '__hash__',\n",
              " '__init__',\n",
              " '__init_subclass__',\n",
              " '__ior__',\n",
              " '__iter__',\n",
              " '__le__',\n",
              " '__len__',\n",
              " '__lt__',\n",
              " '__module__',\n",
              " '__ne__',\n",
              " '__new__',\n",
              " '__or__',\n",
              " '__reduce__',\n",
              " '__reduce_ex__',\n",
              " '__repr__',\n",
              " '__reversed__',\n",
              " '__ror__',\n",
              " '__setattr__',\n",
              " '__setitem__',\n",
              " '__sizeof__',\n",
              " '__str__',\n",
              " '__subclasshook__',\n",
              " '__weakref__',\n",
              " '_check_values_features',\n",
              " '_check_values_type',\n",
              " 'align_labels_with_mapping',\n",
              " 'cache_files',\n",
              " 'cast',\n",
              " 'cast_column',\n",
              " 'class_encode_column',\n",
              " 'cleanup_cache_files',\n",
              " 'clear',\n",
              " 'column_names',\n",
              " 'copy',\n",
              " 'data',\n",
              " 'filter',\n",
              " 'flatten',\n",
              " 'flatten_indices',\n",
              " 'formatted_as',\n",
              " 'from_csv',\n",
              " 'from_json',\n",
              " 'from_parquet',\n",
              " 'from_text',\n",
              " 'fromkeys',\n",
              " 'get',\n",
              " 'items',\n",
              " 'keys',\n",
              " 'load_from_disk',\n",
              " 'map',\n",
              " 'num_columns',\n",
              " 'num_rows',\n",
              " 'pop',\n",
              " 'popitem',\n",
              " 'push_to_hub',\n",
              " 'remove_columns',\n",
              " 'rename_column',\n",
              " 'rename_columns',\n",
              " 'reset_format',\n",
              " 'save_to_disk',\n",
              " 'select_columns',\n",
              " 'set_format',\n",
              " 'set_transform',\n",
              " 'setdefault',\n",
              " 'shape',\n",
              " 'shuffle',\n",
              " 'sort',\n",
              " 'unique',\n",
              " 'update',\n",
              " 'values',\n",
              " 'with_format',\n",
              " 'with_transform']"
            ]
          },
          "execution_count": 109,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "dir(ds)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sLlmQhlu35SG"
      },
      "source": [
        "# Q3"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZPLNuENJ0_am",
        "outputId": "b592d2f6-3abc-4784-87ab-d32cfb3f2097"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Size in memory: 678.65 MB\n"
          ]
        }
      ],
      "source": [
        "def check_size(ds):\n",
        "  size = 0\n",
        "  for split in ds.keys():\n",
        "    size += ds[split].info.size_in_bytes\n",
        "\n",
        "  memory = size / (1024**2)\n",
        "  print(f\"Size in memory: {memory:.2f} MB\")\n",
        "check_size(ds)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3HtzjZX32ehe",
        "outputId": "4a7862cf-2d1f-4f40-c51d-74c42a300197"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Dataset({\n",
              "    features: ['tokens', 'ner_tags'],\n",
              "    num_rows: 497882\n",
              "})"
            ]
          },
          "execution_count": 111,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "ds['train']"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PHZtemXY6mYc"
      },
      "source": [
        "# Q5"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WYrsWz5K4FSF",
        "outputId": "4aaa5ed1-963d-4a91-e0f8-8e4c8899652a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Current--> train: 5959032\n",
            "Current--> test: 9528\n",
            "Current--> validation: 33316\n",
            "Total tokens in validation: 6001876\n"
          ]
        }
      ],
      "source": [
        "def add_len_feature(df):\n",
        "    df[\"num tokens\"] = len(df[\"tokens\"])\n",
        "    return df\n",
        "\n",
        "tok_sum = 0\n",
        "new_ds = {}  # Initialize a dictionary to store the modified datasets\n",
        "\n",
        "for split in ds.keys():\n",
        "    ds_cur = ds[split].map(add_len_feature)\n",
        "    temp = sum(ds_cur[\"num tokens\"])\n",
        "    tok_sum += temp\n",
        "    new_ds[split] = ds_cur  # Store the modified dataset in the new variable\n",
        "    print(f\"Current--> {split}: {temp}\")\n",
        "\n",
        "print(f\"Total tokens in {split}: {tok_sum}\")\n",
        "\n",
        "# Convert the dictionary into a DatasetDict\n",
        "from datasets import DatasetDict\n",
        "new_ds = DatasetDict(new_ds)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rBrNbE_X6uyu"
      },
      "source": [
        "# Q6"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cM083Nk75iXD",
        "outputId": "1c3f179c-3cc4-4a7b-e831-5dd4b333e511"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Size in memory: 678.65 MB\n"
          ]
        }
      ],
      "source": [
        "check_size(new_ds)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NIDBM8uV9_jB"
      },
      "source": [
        "# Q7"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PobPlbDS8Mdj"
      },
      "outputs": [],
      "source": [
        "def join_tokens(ds):\n",
        "  ds[\"text\"] = \" \".join(ds[\"tokens\"])\n",
        "  return ds\n",
        "\n",
        "ds_join = {}\n",
        "for split in ds.keys():\n",
        "  ds_cur = ds[split].map(join_tokens)\n",
        "  ds_cur = ds_cur.remove_columns([\"tokens\", \"ner_tags\"])\n",
        "  ds_join[split] = ds_cur\n",
        "\n",
        "ds = DatasetDict(ds_join)\n",
        "\n",
        "# ds_join = ds.map(join_tokens)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9Mgkl0E_9Vr6",
        "outputId": "be8d4818-d921-4f59-cb1e-15c6b4ec1908"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Total number of samples in ds: 501435\n"
          ]
        }
      ],
      "source": [
        "# Get the total number of samples in the new dataset\n",
        "total_samples = sum(len(ds[split]) for split in ds.keys())\n",
        "print(f\"Total number of samples in ds: {total_samples}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EYN0vKNHBwNS",
        "outputId": "fdd6f9fa-1d42-4122-aba1-229d131dc254"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'text': 'பைரவருக்கு தேய்பிறை அஷ்டமியில் விசேஷ அபிஷேக ஆராதனைகள் நடைபெறுகின்றன .'}"
            ]
          },
          "execution_count": 73,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "ds[\"train\"][0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8ESZl7FgCXTX",
        "outputId": "bdaeb0a7-b8c5-45dd-d801-f45aae049d15"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'train': [{'filename': '/root/.cache/huggingface/datasets/ai4bharat___naamapadam/ta/1.0.0/9d4f21ac57d11ed4f9ea64854fdc9f5618e61acc/cache-6fa5c2925a90a2d2.arrow'}],\n",
              " 'test': [{'filename': '/root/.cache/huggingface/datasets/ai4bharat___naamapadam/ta/1.0.0/9d4f21ac57d11ed4f9ea64854fdc9f5618e61acc/cache-f847a9d1fc817fde.arrow'}],\n",
              " 'validation': [{'filename': '/root/.cache/huggingface/datasets/ai4bharat___naamapadam/ta/1.0.0/9d4f21ac57d11ed4f9ea64854fdc9f5618e61acc/cache-a4d379fb3e2138a7.arrow'}]}"
            ]
          },
          "execution_count": 74,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "ds.cache_files"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vesEzidQF8S2"
      },
      "source": [
        "# Q9"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OQmk5IuzDX_V"
      },
      "outputs": [],
      "source": [
        "ds_filter = dict()\n",
        "\n",
        "for split in ds.keys():\n",
        "  ds_filter[split] = ds[split].filter(lambda x: len(x[\"text\"]) >= 6)\n",
        "\n",
        "ds_filter = DatasetDict(ds_filter)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rc_3wfAZF5zs",
        "outputId": "d9f780d0-2c51-4f37-f904-fd55eb8eaecb"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "DatasetDict({\n",
              "    train: Dataset({\n",
              "        features: ['text'],\n",
              "        num_rows: 497876\n",
              "    })\n",
              "    test: Dataset({\n",
              "        features: ['text'],\n",
              "        num_rows: 757\n",
              "    })\n",
              "    validation: Dataset({\n",
              "        features: ['text'],\n",
              "        num_rows: 2795\n",
              "    })\n",
              "})"
            ]
          },
          "execution_count": 117,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "ds_filter"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ctyatlP6GAA-",
        "outputId": "8c5c291f-3356-4fd1-d495-142186ba7f13"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "501428"
            ]
          },
          "execution_count": 118,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "sum(len(ds_filter[split]) for split in ds_filter.keys())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_E24waRSGnt4"
      },
      "source": [
        "# Q10"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zSJL5ECsGuTf",
        "outputId": "ef75fc7d-5d43-4ad4-bd3e-24de80d7403e"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['actsa-sc.te',\n",
              " 'bbca.hi',\n",
              " 'copa.en',\n",
              " 'copa.gu',\n",
              " 'copa.hi',\n",
              " 'copa.mr',\n",
              " 'csqa.as',\n",
              " 'csqa.bn',\n",
              " 'csqa.gu',\n",
              " 'csqa.hi',\n",
              " 'csqa.kn',\n",
              " 'csqa.ml',\n",
              " 'csqa.mr',\n",
              " 'csqa.or',\n",
              " 'csqa.pa',\n",
              " 'csqa.ta',\n",
              " 'csqa.te',\n",
              " 'cvit-mkb-clsr.en-bn',\n",
              " 'cvit-mkb-clsr.en-gu',\n",
              " 'cvit-mkb-clsr.en-hi',\n",
              " 'cvit-mkb-clsr.en-ml',\n",
              " 'cvit-mkb-clsr.en-mr',\n",
              " 'cvit-mkb-clsr.en-or',\n",
              " 'cvit-mkb-clsr.en-ta',\n",
              " 'cvit-mkb-clsr.en-te',\n",
              " 'cvit-mkb-clsr.en-ur',\n",
              " 'iitp-mr.hi',\n",
              " 'iitp-pr.hi',\n",
              " 'inltkh.gu',\n",
              " 'inltkh.ml',\n",
              " 'inltkh.mr',\n",
              " 'inltkh.ta',\n",
              " 'inltkh.te',\n",
              " 'md.hi',\n",
              " 'sna.bn',\n",
              " 'wiki-ner.as',\n",
              " 'wiki-ner.bn',\n",
              " 'wiki-ner.gu',\n",
              " 'wiki-ner.hi',\n",
              " 'wiki-ner.kn',\n",
              " 'wiki-ner.ml',\n",
              " 'wiki-ner.mr',\n",
              " 'wiki-ner.or',\n",
              " 'wiki-ner.pa',\n",
              " 'wiki-ner.ta',\n",
              " 'wiki-ner.te',\n",
              " 'wnli.en',\n",
              " 'wnli.gu',\n",
              " 'wnli.hi',\n",
              " 'wnli.mr',\n",
              " 'wstp.as',\n",
              " 'wstp.bn',\n",
              " 'wstp.gu',\n",
              " 'wstp.hi',\n",
              " 'wstp.kn',\n",
              " 'wstp.ml',\n",
              " 'wstp.mr',\n",
              " 'wstp.or',\n",
              " 'wstp.pa',\n",
              " 'wstp.ta',\n",
              " 'wstp.te']"
            ]
          },
          "execution_count": 119,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "get_dataset_config_names(\"ai4bharat/indic_glue\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sUt8OZHlGOFl"
      },
      "outputs": [],
      "source": [
        "dataset = load_dataset(\"ai4bharat/indic_glue\", 'inltkh.ta')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iPnqTEnoG1lr",
        "outputId": "773154ee-ec8d-4afd-fbfb-cd0039b51458"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "DatasetDict({\n",
              "    train: Dataset({\n",
              "        features: ['text', 'label'],\n",
              "        num_rows: 5346\n",
              "    })\n",
              "    validation: Dataset({\n",
              "        features: ['text', 'label'],\n",
              "        num_rows: 669\n",
              "    })\n",
              "    test: Dataset({\n",
              "        features: ['text', 'label'],\n",
              "        num_rows: 669\n",
              "    })\n",
              "})"
            ]
          },
          "execution_count": 86,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0BMVrkmxG8Hk",
        "outputId": "20f58a5c-d7f7-4677-9a96-63b1907f8e84"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'text': ['கே.வி.ஆனந்தே ட்விட்டரில் இதை அறிவித்துள்ளார். இந்தப் படத்துக்கு கேவ்மிக் ஆரி ஒளிப்பதிவு செய்ய, ஹாரிஸ் ஜெயராஜ் இசையமைக்கிறார். பட்டுக்கோட்டை பிரபாகர் வசனம் எழுத, கலை இயக்குநராக கிரண் பணியாற்றுகிறார். இந்தப் படத்தை லைகா புரொடக்\\u200cஷன்ஸ் நிறுவனம் தயாரிக்கிறது.',\n",
              "  'பரிகாரம்: சுக்கிரன், கேதுவுக்குப் பிரீதி, பரிகாரங்கள் செய்து கொள்ளவும்.',\n",
              "  '8 லட்சம் கார்களை திரும்பப் பெற்றது ஹோண்டா நிறுவனம்',\n",
              "  '2003-ம் ஆண்டு அக்டோபர் மாதத்திலிருந்து 2013-ம் ஆண்டு மார்ச் மாதம் வரை ஜெனரல் டைனமிக் கார்ப்பரேஷன் நிறுவனத்தின் நிர்வாகத் துணைத்தலைவர் பொறுப்பில் இருந்தவர்.',\n",
              "  'தொழில் வியாபாரத்தில் பணத்தேவை ஏற்படலாம். கடன் விவகாரங்களில் கவனமாக செயல்படுவது நல்லது. உத்தியோகத்தில் இருப்பவர்கள் ஓய்வு இல்லாமல் பணியாற்ற வேண்டி இருக்கும். இயந்திரம், நெருப்பு, ஆயுதத்தை பயன்படுத்துவோர் மிகவும் கவனமாக இருப்பது அவசியம்.'],\n",
              " 'label': [6, 5, 1, 1, 5]}"
            ]
          },
          "execution_count": 87,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "dataset[\"train\"][:5]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "woAEDfFIHaMq",
        "outputId": "97595524-3505-4508-83be-292d2e62c777"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Total number of samples after interleaving: 25890\n"
          ]
        }
      ],
      "source": [
        "from datasets import load_dataset, interleave_datasets\n",
        "\n",
        "# Load naamapadam dataset (assuming it's already filtered for >=6 words)\n",
        "ds_naamapadam = ds  # Assuming this is your filtered naamapadam dataset\n",
        "\n",
        "# Load the Tamil sub-dataset from indic_glue\n",
        "ds_indic_glue = load_dataset(\"ai4bharat/indic_glue\", \"inltkh.ta\")\n",
        "\n",
        "# Define the word filter function to filter the dataset with >=6 words\n",
        "def word_filter(ds):\n",
        "    temp = ds[\"text\"].split(\" \")\n",
        "    return len(temp) >= 6\n",
        "\n",
        "# Apply filter to indic_glue dataset\n",
        "filtered_indic_glue = ds_indic_glue[\"train\"].filter(word_filter)\n",
        "\n",
        "# Interleave datasets with 80% samples from naamapadam and 20% from indic_glue\n",
        "ds_interleaved = interleave_datasets(\n",
        "    [ds_naamapadam[\"train\"], filtered_indic_glue],\n",
        "    probabilities=[0.8, 0.2],\n",
        "    seed=42\n",
        ")\n",
        "\n",
        "# Get the number of samples in the interleaved dataset\n",
        "num_samples = len(ds_interleaved)\n",
        "print(f\"Total number of samples after interleaving: {num_samples}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Yugyk5S8JtSq",
        "outputId": "1d697c93-d2d2-435d-bfac-fcb6db8b7a1f"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Dataset({\n",
              "    features: ['text', 'label'],\n",
              "    num_rows: 5153\n",
              "})"
            ]
          },
          "execution_count": 101,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "filtered_indic_glue"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LJvspko6Mz8n"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
